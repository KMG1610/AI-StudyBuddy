{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KMhEhruXUpI_"
      },
      "outputs": [],
      "source": [
        "# Install the Google Generative AI library and Gradio for the UI\n",
        "!pip install -q -U google-generativeai gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- CONFIGURATION & AUTO-DETECT ---\n",
        "print(\"--- STARTING CONFIGURATION ---\")\n",
        "try:\n",
        "    # 1. Load API Key\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=API_KEY)\n",
        "\n",
        "    # 2. Auto-Detect Available Model\n",
        "    # We ask Google: \"Give us all models that support generating text\"\n",
        "    available_models = []\n",
        "    for m in genai.list_models():\n",
        "        if 'generateContent' in m.supported_generation_methods:\n",
        "            available_models.append(m.name)\n",
        "\n",
        "    # 3. Select the best available model\n",
        "    if not available_models:\n",
        "        raise ValueError(\"No compatible Gemini models found for your API Key.\")\n",
        "\n",
        "    # Prefer newer models if available, otherwise take the first one\n",
        "    # We look for 'flash' (fast) or 'pro' (smart)\n",
        "    selected_model_name = next((m for m in available_models if 'flash' in m), available_models[0])\n",
        "\n",
        "    model = genai.GenerativeModel(selected_model_name)\n",
        "    print(f\"‚úÖ SUCCESSFULLY CONFIGURED using model: {selected_model_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå CONFIG ERROR: {e}\")\n",
        "    print(\"Please check your API Key and ensure 'Notebook Access' is ON in Secrets.\")\n",
        "    model = None\n",
        "\n",
        "# --- CORE FUNCTIONS ---\n",
        "def study_buddy_logic(input_text, mode):\n",
        "    if model is None:\n",
        "        return \"‚ùå Error: API is not configured. Check the logs above.\"\n",
        "\n",
        "    print(f\"\\nüîò BUTTON CLICKED! Mode: {mode}\")\n",
        "\n",
        "    if not input_text.strip():\n",
        "        return \"‚ö†Ô∏è Please enter some text first!\"\n",
        "\n",
        "    # Defining prompts\n",
        "    prompts = {\n",
        "        \"Explain Concept\": f\"Act as an expert tutor. Explain this in simple terms:\\n\\n{input_text}\",\n",
        "        \"Summarize Notes\": f\"Summarize these notes into bullet points:\\n\\n{input_text}\",\n",
        "        \"Generate Quiz\": f\"Create 3 multiple choice questions with answers at the end based on:\\n\\n{input_text}\",\n",
        "        \"Create Flashcards\": f\"Create 5 Q&A flashcards based on:\\n\\n{input_text}\"\n",
        "    }\n",
        "\n",
        "    # Calling AI\n",
        "    try:\n",
        "        print(f\"‚è≥ Sending request to {model.model_name}...\")\n",
        "        response = model.generate_content(prompts[mode])\n",
        "        print(\"‚úÖ AI Responded!\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå API ERROR: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "# --- UI SETUP ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"# üéì AI Study Buddy\")\n",
        "\n",
        "    user_input = gr.Textbox(lines=5, label=\"1. Paste Study Material Here\")\n",
        "\n",
        "    mode_selector = gr.Radio(\n",
        "        [\"Explain Concept\", \"Summarize Notes\", \"Generate Quiz\", \"Create Flashcards\"],\n",
        "        label=\"2. Choose Mode\", value=\"Explain Concept\"\n",
        "    )\n",
        "\n",
        "    submit_btn = gr.Button(\"üöÄ Run AI\", variant=\"primary\")\n",
        "\n",
        "    output_display = gr.Markdown(label=\"3. AI Output Result\")\n",
        "\n",
        "    submit_btn.click(fn=study_buddy_logic, inputs=[user_input, mode_selector], outputs=output_display)\n",
        "\n",
        "print(\"--- LAUNCHING APP ---\")\n",
        "app.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tT4YzFCjUvzO",
        "outputId": "c0a1849a-ee1b-4abf-c467-e382c7845143"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING CONFIGURATION ---\n",
            "‚úÖ SUCCESSFULLY CONFIGURED using model: models/gemini-2.5-flash\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3792094714.py:68: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as app:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAUNCHING APP ---\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://da16792829fea9dc65.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://da16792829fea9dc65.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîò BUTTON CLICKED! Mode: Summarize Notes\n",
            "‚è≥ Sending request to models/gemini-2.5-flash...\n",
            "‚úÖ AI Responded!\n",
            "\n",
            "üîò BUTTON CLICKED! Mode: Explain Concept\n",
            "‚è≥ Sending request to models/gemini-2.5-flash...\n",
            "‚úÖ AI Responded!\n",
            "\n",
            "üîò BUTTON CLICKED! Mode: Generate Quiz\n",
            "‚è≥ Sending request to models/gemini-2.5-flash...\n",
            "‚úÖ AI Responded!\n",
            "\n",
            "üîò BUTTON CLICKED! Mode: Create Flashcards\n",
            "‚è≥ Sending request to models/gemini-2.5-flash...\n",
            "‚úÖ AI Responded!\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://da16792829fea9dc65.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sde85lzWup9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
